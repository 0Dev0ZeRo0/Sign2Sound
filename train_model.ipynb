{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cc9769-1c91-4eb2-81fd-168967505cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25000, Loss: 1.7948, Accuracy: 0.2083\n",
      "Epoch 2/25000, Loss: 1.7715, Accuracy: 0.2083\n",
      "Epoch 3/25000, Loss: 1.7608, Accuracy: 0.2083\n",
      "Epoch 4/25000, Loss: 1.7440, Accuracy: 0.3542\n",
      "Epoch 5/25000, Loss: 1.7109, Accuracy: 0.3542\n",
      "Epoch 6/25000, Loss: 1.6768, Accuracy: 0.4375\n",
      "Epoch 7/25000, Loss: 1.6406, Accuracy: 0.5000\n",
      "Epoch 8/25000, Loss: 1.6073, Accuracy: 0.3750\n",
      "Epoch 9/25000, Loss: 1.5672, Accuracy: 0.3750\n",
      "Epoch 10/25000, Loss: 1.5335, Accuracy: 0.3750\n",
      "Epoch 11/25000, Loss: 1.4791, Accuracy: 0.4375\n",
      "Epoch 12/25000, Loss: 1.4233, Accuracy: 0.5208\n",
      "Epoch 13/25000, Loss: 1.3893, Accuracy: 0.5000\n",
      "Epoch 14/25000, Loss: 1.3923, Accuracy: 0.4375\n",
      "Epoch 15/25000, Loss: 1.2717, Accuracy: 0.4792\n",
      "Epoch 16/25000, Loss: 1.2414, Accuracy: 0.6667\n",
      "Epoch 17/25000, Loss: 1.1721, Accuracy: 0.7292\n",
      "Epoch 18/25000, Loss: 1.0808, Accuracy: 0.7083\n",
      "Epoch 19/25000, Loss: 1.0662, Accuracy: 0.8125\n",
      "Epoch 20/25000, Loss: 1.0262, Accuracy: 0.7292\n",
      "Epoch 21/25000, Loss: 0.9672, Accuracy: 0.6667\n",
      "Epoch 22/25000, Loss: 0.8793, Accuracy: 0.7292\n",
      "Epoch 23/25000, Loss: 0.8560, Accuracy: 0.7292\n",
      "Epoch 24/25000, Loss: 0.7808, Accuracy: 0.7292\n",
      "Epoch 25/25000, Loss: 0.7891, Accuracy: 0.7083\n",
      "Epoch 26/25000, Loss: 0.7375, Accuracy: 0.7292\n",
      "Epoch 27/25000, Loss: 0.7349, Accuracy: 0.6875\n",
      "Epoch 28/25000, Loss: 0.9472, Accuracy: 0.5625\n",
      "Epoch 29/25000, Loss: 0.8038, Accuracy: 0.7083\n",
      "Epoch 30/25000, Loss: 0.7857, Accuracy: 0.6458\n",
      "Epoch 31/25000, Loss: 0.7454, Accuracy: 0.6667\n",
      "Epoch 32/25000, Loss: 0.6963, Accuracy: 0.6458\n",
      "Epoch 33/25000, Loss: 0.6155, Accuracy: 0.6875\n",
      "Epoch 34/25000, Loss: 0.5727, Accuracy: 0.6875\n",
      "Epoch 35/25000, Loss: 0.6044, Accuracy: 0.6458\n",
      "Epoch 36/25000, Loss: 0.7436, Accuracy: 0.6667\n",
      "Epoch 37/25000, Loss: 0.9340, Accuracy: 0.6250\n",
      "Epoch 38/25000, Loss: 0.9831, Accuracy: 0.5625\n",
      "Epoch 39/25000, Loss: 0.9280, Accuracy: 0.5417\n",
      "Epoch 40/25000, Loss: 1.0958, Accuracy: 0.5208\n",
      "Epoch 41/25000, Loss: 0.8006, Accuracy: 0.6250\n",
      "Epoch 42/25000, Loss: 0.7334, Accuracy: 0.7083\n",
      "Epoch 43/25000, Loss: 0.6906, Accuracy: 0.8125\n",
      "Epoch 44/25000, Loss: 0.6839, Accuracy: 0.7708\n",
      "Epoch 45/25000, Loss: 0.6588, Accuracy: 0.6667\n",
      "Epoch 46/25000, Loss: 0.6752, Accuracy: 0.7917\n",
      "Epoch 47/25000, Loss: 0.5992, Accuracy: 0.8125\n",
      "Epoch 48/25000, Loss: 0.5603, Accuracy: 0.8125\n",
      "Epoch 49/25000, Loss: 0.5259, Accuracy: 0.9167\n",
      "Epoch 50/25000, Loss: 0.5412, Accuracy: 0.9167\n",
      "Epoch 51/25000, Loss: 0.6275, Accuracy: 0.8333\n",
      "Epoch 52/25000, Loss: 0.5374, Accuracy: 0.8750\n",
      "Epoch 53/25000, Loss: 0.4794, Accuracy: 0.9583\n",
      "Accuracy 0.9583 reached threshold 0.95. Terminating training.\n",
      "Model saved to models/sign_lstm.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size1, hidden_size2, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(hidden_size2, hidden_size3, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size3, 64)\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x[:, -1, :]\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Paths and parameters\n",
    "DATA_PATH = 'processed_data'\n",
    "MODEL_PATH = 'models/sign_lstm.pth'\n",
    "INPUT_SIZE = 225  # 21*3*2 + 33*3\n",
    "HIDDEN_SIZE1 = 128\n",
    "HIDDEN_SIZE2 = 64\n",
    "HIDDEN_SIZE3 = 32\n",
    "OUTPUT_SIZE = 6  \n",
    "EPOCHS = 25000\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "ACCURACY_THRESHOLD = 0.95  \n",
    "\n",
    "def load_data():\n",
    "    X_train = np.load(os.path.join(DATA_PATH, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(DATA_PATH, 'y_train.npy'))\n",
    "    X_test = np.load(os.path.join(DATA_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(DATA_PATH, 'y_test.npy'))\n",
    "    labels = np.load(os.path.join(DATA_PATH, 'labels.npy'))\n",
    "    \n",
    "    if len(labels) != OUTPUT_SIZE:\n",
    "        print(f\"Error: Expected {OUTPUT_SIZE} signs, found {len(labels)}\")\n",
    "        raise ValueError(\"Incorrect number of signs\")\n",
    "    \n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, labels\n",
    "\n",
    "def train_model():\n",
    "    X_train, y_train, X_test, y_test, labels = load_data()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE1, HIDDEN_SIZE2, HIDDEN_SIZE3, OUTPUT_SIZE).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9)  # Decay LR by 0.9 every 50 epochs\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "\n",
    "                if y_batch.dim() > 1:\n",
    "                    y_batch = torch.argmax(y_batch, axis=1)\n",
    "\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_predictions += (preds == y_batch).sum().item()\n",
    "                total_samples += y_batch.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "            writer.add_scalar(\"Loss/Train\", epoch_loss, epoch)\n",
    "            writer.add_scalar(\"Accuracy/Train\", epoch_accuracy, epoch)\n",
    "            writer.add_scalar(\"Learning Rate\", optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            # Early termination based on accuracy threshold\n",
    "            if epoch_accuracy >= ACCURACY_THRESHOLD:\n",
    "                print(f\"Accuracy {epoch_accuracy:.4f} reached threshold {ACCURACY_THRESHOLD}. Terminating training.\")\n",
    "                os.makedirs('models', exist_ok=True)\n",
    "                torch.save(model.state_dict(), MODEL_PATH)\n",
    "                print(f\"Model saved to {MODEL_PATH}\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nKeyboard interrupt detected. Saving model before termination...\")\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"Model saved to {MODEL_PATH} at interruption.\")\n",
    "    finally:\n",
    "        # Ensure model is saved if training completes without reaching threshold or is interrupted\n",
    "        if not os.path.exists(MODEL_PATH):\n",
    "            os.makedirs('models', exist_ok=True)\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Training interrupted or completed without threshold. Model saved to {MODEL_PATH}\")\n",
    "        writer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a48087-8adc-4d8c-a1a6-197f13ea0123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpy-torch)",
   "language": "python",
   "name": "gpu-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
