{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd67afac-6d96-4aaa-82ac-e12485a3bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for sign: One\n",
      "  Video 1/30. Press 's' to start, 'q' to quit.\n",
      "  Recording...\n",
      "  Done recording video.\n",
      "  Video 2/30. Press 's' to start, 'q' to quit.\n",
      "  Recording...\n",
      "  Done recording video.\n",
      "  Video 3/30. Press 's' to start, 'q' to quit.\n",
      "  Recording...\n",
      "  Done recording video.\n",
      "  Video 4/30. Press 's' to start, 'q' to quit.\n",
      "  Recording...\n",
      "  Done recording video.\n",
      "  Video 5/30. Press 's' to start, 'q' to quit.\n",
      "  Recording...\n",
      "  Done recording video.\n",
      "  Video 6/30. Press 's' to start, 'q' to quit.\n",
      "  Recording...\n",
      "  Done recording video.\n",
      "  Video 7/30. Press 's' to start, 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7)\n",
    "## here modify to capture only those signs and be sure to mention the words you did sign for and also download those videos so i can learn what it is\n",
    "SIGNS = [\n",
    "    'One'\n",
    "]\n",
    "## 50 frams for one data, and for each data i need 30 times of it\n",
    "DATASET_PATH = 'dataset'\n",
    "FRAMES_PER_VIDEO = 30\n",
    "NUM_VIDEOS = 30\n",
    "\n",
    "def extract_landmarks(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    hand_results = hands.process(image_rgb)\n",
    "    pose_results = pose.process(image_rgb)\n",
    "    \n",
    "    landmarks = []\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks[:2]:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "        landmarks.extend([0] * (21 * 3 * (2 - len(hand_results.multi_hand_landmarks))))\n",
    "    else:\n",
    "        landmarks.extend([0] * (21 * 3 * 2))\n",
    "    \n",
    "    if pose_results.pose_landmarks:\n",
    "        for i, lm in enumerate(pose_results.pose_landmarks.landmark):\n",
    "            if i < 33:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "    else:\n",
    "        landmarks.extend([0] * (33 * 3))\n",
    "    \n",
    "    landmarks = np.array(landmarks)\n",
    "    expected_landmarks = 225  # 21*3*2 + 33*3\n",
    "    if len(landmarks) != expected_landmarks:\n",
    "        if len(landmarks) < expected_landmarks:\n",
    "            landmarks = np.pad(landmarks, (0, expected_landmarks - len(landmarks)), mode='constant')\n",
    "        else:\n",
    "            landmarks = landmarks[:expected_landmarks]\n",
    "    \n",
    "    return landmarks\n",
    "\n",
    "def collect_data(signs_to_collect=SIGNS):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    for sign in signs_to_collect:\n",
    "        sign_path = os.path.join(DATASET_PATH, sign)\n",
    "        os.makedirs(sign_path, exist_ok=True)\n",
    "        \n",
    "        print(f\"Collecting data for sign: {sign}\")\n",
    "        for video_idx in range(NUM_VIDEOS):\n",
    "            video_path = os.path.join(sign_path, f\"video_{video_idx}\")\n",
    "            os.makedirs(video_path, exist_ok=True)\n",
    "            \n",
    "            print(f\"  Video {video_idx + 1}/{NUM_VIDEOS}. Press 's' to start, 'q' to quit.\")\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error: Failed to capture frame\")\n",
    "                    break\n",
    "                cv2.putText(frame, f\"Sign: {sign}, Video: {video_idx + 1}, Press 's'\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow('Data Collection', frame)\n",
    "                \n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('s'):\n",
    "                    break\n",
    "                elif key == ord('q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    hands.close()\n",
    "                    pose.close()\n",
    "                    return\n",
    "            \n",
    "            print(\"  Recording...\")\n",
    "            for frame_idx in range(FRAMES_PER_VIDEO):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error: Failed to capture frame\")\n",
    "                    break\n",
    "                \n",
    "                landmarks = extract_landmarks(frame)\n",
    "                frame_path = os.path.join(video_path, f\"frame_{frame_idx}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                \n",
    "                cv2.putText(frame, f\"Sign: {sign}, Frame: {frame_idx + 1}/{FRAMES_PER_VIDEO}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow('Data Collection', frame)\n",
    "                cv2.waitKey(33)  # ~30 fps\n",
    "                \n",
    "            print(\"  Done recording video.\")\n",
    "            time.sleep(1)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    hands.close()\n",
    "    pose.close()\n",
    "    print(\"Data collection complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6909d-c6aa-4526-885a-b677d663d03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b24d02-7213-4b91-b5d3-f1372f91b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backup of full\n",
    "SIGNS = [\n",
    "    'Hello', 'Great', 'Sunny', 'Brave', 'Kind', 'Happy', 'Strong', 'Wise', 'Gentle', 'Bright',\n",
    "    'Calm', 'Quick', 'Warm', 'Clear', 'Bold', 'Sweet', 'Pure', 'Vivid', 'Steady', 'Lively',\n",
    "    'Soft', 'True', 'Deep', 'Light', 'Fast', 'Cool', 'High', 'Smooth', 'Rich', 'Quiet',\n",
    "    'Firm', 'New', 'Old', 'Young', 'Safe', 'Wild', 'Hot', 'Cold', 'Dry', 'Wet',\n",
    "    'Early', 'Late', 'Near', 'Far', 'Full', 'Empty', 'Sharp', 'Dull', 'Loud', 'I'\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a56f4c7-2258-450c-bbe9-4972c61595e3",
   "metadata": {},
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f92734-e63d-45f2-a0a5-964b89383662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.20\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82416d5-6349-4e0f-8f0d-fc3e75da4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57fb61-59f2-4d2d-b473-4a5e0fd1f498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpy-torch)",
   "language": "python",
   "name": "gpu-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
